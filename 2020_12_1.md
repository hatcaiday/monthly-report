Giả sử bạn có một trang web có 1000 request truy cập cùng một lúc, và request nào cũng lấy dữ liệu trong database. Và sẽ ra sao nếu trang của bạn liên tục show ra thế này?

Lúc này bạn có thể nghĩ đến việc tận dụng memory caching để cache lại dữ liệu

## 1. Memory cache là gì?
Memory caching (bộ nhớ đệm) là một kỹ thuật trong đó các ứng dụng máy tính lưu trữ tạm thời dữ liệu trên bộ nhớ chính của máy tính (RAM - random access memory (bộ nhớ truy cập ngẫu nhiên)) để truy xuất nhanh dữ liệu đó. RAM được sử dụng để lưu trữ tạm thời là bộ nhớ cache (bộ nhớ đệm). Vì khi truy cập vào RAM sẽ nhanh hơn đáng kể so với truy cập vào đĩa cứng hay mạng, bộ nhớ đệm giúp các ứng dụng chạy nhanh hơn do truy cập dữ liệu nhanh hơn.

Bộ nhớ đệm đặc biệt hiệu quả khi ứng dụng thể hiện một pattern chung, trong đó truy cập nhiều lần vào dữ liệu đã truy cập trước đó. Bộ nhớ đệm cũng được sử dụng để lưu trữ các phép tính dữ liệu tốn thời gian để tính toán. Bằng cách lưu trữ các phép tính trong bộ nhớ đệm, hệ thống tiết kiệm thời gian bằng cách tránh lặp lại các phép tính.

## 2. Memory caching hoạt động thế nào?

Bộ nhớ đệm hoạt động dựa vào lần đầu cài đặt một portion của RAM được sử dụng như môt cache. Như một ứng dụng sử dụng để lấy data

Bộ nhớ đệm hoạt động bằng cách đầu tiên dành một phần RAM được sử dụng làm bộ nhớ đệm. Khi một ứng dụng cố gắng đọc dữ liệu, thường từ một hệ thống lưu trữ dữ liệu như cơ sở dữ liệu, nó sẽ kiểm tra xem liệu bản ghi mong muốn đã tồn tại trong bộ nhớ cache hay chưa. Nếu có, thì ứng dụng sẽ đọc dữ liệu từ bộ nhớ cache, do đó loại bỏ việc truy cập cơ sở dữ liệu chậm hơn. Nếu bản ghi mong muốn không có trong bộ nhớ cache, thì ứng dụng sẽ đọc bản ghi từ nguồn. Khi lấy dữ liệu đó, nó cũng ghi dữ liệu vào bộ nhớ đệm để khi ứng dụng cần cùng dữ liệu đó trong tương lai, nó có thể nhanh chóng lấy nó từ bộ nhớ đệm.


Vì bộ nhớ đệm có kích thước hạn chế, cuối cùng một số dữ liệu đã có trong bộ đệm sẽ phải bị xóa để nhường chỗ cho dữ liệu mới mà ứng dụng đã truy cập gần đây nhất. Điều này có nghĩa là hệ thống bộ nhớ đệm cần một chiến lược mà các bản ghi cần loại bỏ để tạo khoảng trống. Chiến lược này sẽ phụ thuộc vào bản chất của các quyền truy cập dữ liệu của ứng dụng và nói chung sẽ cố gắng xóa các bản ghi mà dự kiến ​​sẽ sớm được truy cập lại. Ví dụ: chiến lược ít được sử dụng gần đây nhất (LRU) sẽ xóa bản ghi có lần truy cập cuối cùng trước bất kỳ bản ghi nào khác trong bộ nhớ cache. Giả định ở đây là nếu đã lâu không được truy cập vào bản ghi, thì rất có thể nó sẽ không sớm được truy cập lại. Hay nói một cách khác, các bản ghi được sử dụng nhiều nhất gần đây có thể sẽ sớm được sử dụng lại. Chiến lược ít được sử dụng nhất (LFU) đòi hỏi phải theo dõi số lần truy cập của mỗi bản ghi trong bộ đệm và xóa bản ghi có số lượng truy cập ít nhất. Giả định ở đây là một bản ghi không thường xuyên được sử dụng sẽ không sớm được sử dụng lại.


Thách thức với bộ nhớ đệm là làm thế nào để giảm thiểu “lần bỏ lỡ bộ nhớ cache”, tức là ứng dụng đã cố gắng đọc các bản ghi không có trong bộ nhớ đệm. Nếu bạn có quá nhiều lần bỏ lỡ, hiệu quả của bộ nhớ cache sẽ giảm. Một ứng dụng chỉ đọc dữ liệu mới sẽ không được hưởng lợi từ bộ nhớ cache và trên thực tế, sẽ có hiệu suất thấp hơn do phải thực hiện thêm công việc kiểm tra bộ nhớ cache nhưng không tìm thấy bản ghi mong muốn trong đó. Một cách có thể giảm thiểu thách thức này là tận dụng các bộ nhớ đệm lớn hơn. Điều này thường không thực tế trên một máy tính, đó là lý do tại sao bộ đệm phân tán là lựa chọn phổ biến để tăng tốc các ứng dụng cần truy cập các tập dữ liệu lớn hơn. Bộ nhớ đệm phân tán gộp chung RAM của nhiều máy tính được kết nối trong một cụm để bạn có thể tạo bộ đệm lớn hơn có thể tiếp tục phát triển bằng cách thêm nhiều máy tính hơn vào cụm. Các công nghệ như Hazelcast IMDG có thể được sử dụng như một cụm phân tán để tăng tốc các ứng dụng quy mô lớn.

Một thách thức khác của bộ nhớ đệm là nguy cơ đọc dữ liệu “cũ”, trong đó dữ liệu trong bộ nhớ đệm không phản ánh dữ liệu mới nhất trong nguồn bên dưới. Thông thường, rủi ro này là một sự đánh đổi có thể chấp nhận được vì lợi ích của hiệu suất ứng dụng. Trong trường hợp không, tùy thuộc vào ứng dụng cập nhật nguồn dữ liệu cơ bản để cập nhật bản ghi được đề cập trong bộ nhớ cache.
